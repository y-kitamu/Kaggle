{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use tfrecords\n",
    "TRAIN_TFRECORDS = np.array([str(path) for path in (DATA_ROOT / \"train_tfrecords\").glob(\"*.tfrec\")])\n",
    "TEST_TFRECORDS = np.array([str(path) for path in (DATA_ROOT / \"test_tfrecords\").glob(\"*.tfrec\")])\n",
    "\n",
    "FEATURE_DESCRIPTION = {\n",
    "    'image': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image_name': tf.io.FixedLenFeature([], tf.string),\n",
    "    'target': tf.io.FixedLenFeature([], tf.int64)\n",
    "}\n",
    "\n",
    "\n",
    "def decode_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image\n",
    "\n",
    "\n",
    "def read_tfrecord(example, is_train, n_classes=N_CLASSES):\n",
    "    example = tf.io.parse_single_example(example, FEATURE_DESCRIPTION)\n",
    "    image = decode_image(example[\"image\"])\n",
    "    if is_train:\n",
    "        label = tf.cast(example[\"target\"], tf.int32)\n",
    "        return image, label\n",
    "    image_name = decode_image(example[\"image_name\"])\n",
    "    return image, image_name\n",
    "\n",
    "\n",
    "def load_dataset(filenames, is_train=True, ordered=True):\n",
    "    option = tf.data.Options()\n",
    "    if not ordered:\n",
    "        option.experimental_deterministic = not is_train  # disable order\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n",
    "    dataset = dataset.with_options(option)\n",
    "    dataset = dataset.map(partial(read_tfrecord, is_train=is_train),\n",
    "                          num_parallel_calls=AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_train_dataset(train_tfrecords, batch_size):\n",
    "    train_ds = load_dataset(train_tfrecords, is_train=True, ordered=False)\n",
    "    ds_size = sum(1 for _ in train_ds)\n",
    "    train_ds = train_ds.map(data_augment, num_parallel_calls=AUTOTUNE)\n",
    "    train_ds = train_ds.shuffle(ds_size)\n",
    "    train_ds = train_ds.batch(batch_size).prefetch(AUTOTUNE)\n",
    "    return train_ds\n",
    "    \n",
    "\n",
    "def get_val_dataset(val_tfrecords, batch_size):\n",
    "    val_ds = load_dataset(val_tfrecords, is_train=True, ordered=True)\n",
    "    val_ds = val_ds.batch(batch_size).cache()\n",
    "    val_ds = val_ds.prefetch(AUTOTUNE)\n",
    "    \n",
    "\n",
    "def get_test_dataset(test_tfrecords, batch_size):\n",
    "    test_ds = load_dataset(test_tfrecords, is_train=False, ordered=True)\n",
    "    test_ds = test_ds.batch(batch_size).prefetch(AUTOTUNE)\n",
    "    return test_ds\n",
    "\n",
    "\n",
    "def get_kfold_datasets(train_batch_size, val_batch_size, n_split=5):\n",
    "    kf = KFold(n_splits=n_split)\n",
    "    for train_idx, val_idx in kf.split(TRAIN_TFRECORDS):\n",
    "        train_ds = get_train_dataset(TRAIN_TFRECORDS[train_idx], train_batch_size)\n",
    "        val_ds = get_val_dataset(TRAIN_TFRECORDS[val_idx], val_batch_size)\n",
    "        yield train_ds, val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TFRecordDataset(TRAIN_TFRECORDS, num_parallel_reads=AUTOTUNE)\n",
    "for example in dataset.take(1):\n",
    "    image, label = read_tfrecord(example, is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -e ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "import src\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dir = src.constant.CONFIG_ROOT\n",
    "config_name = \"config_v2.yaml\"\n",
    "\n",
    "cfg = src.utility.run_debug(\n",
    "    lambda: src.utility.load_config(config_name, config_dir)\n",
    ")\n",
    "#cfg.train.val_batch_size = 16\n",
    "src.utility.run_debug(\n",
    "    lambda: src.train.train.train(cfg)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"i : {}\".format(len(glob.glob(\"../data/{}/*.jpg\".fomat(i)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
