{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, OneCycleLR\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')\n",
    "torch.manual_seed(47)\n",
    "np.random.seed(47)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelanomaDataset(Dataset):\n",
    "    def __init__(self, df: str, data: np.array, train: bool = True, transforms = None):\n",
    "        \"\"\"\n",
    "        Class initialization\n",
    "        Args:\n",
    "            df (str): path to pandas.DataFrame \n",
    "            data (np.ndarray): resized images data in a shape of (HxWxC)\n",
    "            train (bool): flag of whether a training dataset is being initialized or testing one\n",
    "            transforms: image transformation method to be applied\n",
    "            \n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(df)\n",
    "        self.data = data\n",
    "        self.transforms = transforms\n",
    "        self.train = train\n",
    "        if self.train:\n",
    "            self.y = self.df['target'].values\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "\n",
    "        if self.transforms:\n",
    "            x = transforms.ToPILImage()(x)\n",
    "            x = self.transforms(x)\n",
    "            \n",
    "        if self.train:\n",
    "            y = self.df.iloc[index]['target']\n",
    "            return x, y\n",
    "        else:\n",
    "            return x\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self, arch):\n",
    "        super(Net, self).__init__()\n",
    "        self.arch = arch\n",
    "        self.arch.fc = nn.Linear(in_features=2048, out_features=1, bias=True)\n",
    "        #self.arch._fc = nn.Linear(in_features=1280, out_features=1, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        No sigmoid in forward because we are going to use BCEWithLogitsLoss\n",
    "        Which applies sigmoid for us when calculating a loss\n",
    "        \"\"\"\n",
    "        x = self.arch(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train = MelanomaDataset(df='/home/kitamura/dataset/Melanoma/train.csv', \n",
    "                        data=np.load('./x_train_224.npy'),\n",
    "                        transforms=transform)\n",
    "skf = StratifiedKFold(n_splits=5, random_state=47, shuffle=True)\n",
    "test = MelanomaDataset(df='/home/kitamura/dataset/Melanoma/test.csv', \n",
    "                       data=np.load('./x_test_224.npy'), \n",
    "                       train=False,\n",
    "                       transforms=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10  # Number of epochs to run\n",
    "model_path = 'model.pth'  # Path and filename to save model to\n",
    "es_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\n",
    "\n",
    "oof = np.zeros((len(train), 1))  # Out Of Fold predictions\n",
    "preds = torch.zeros((len(test), 1), dtype=torch.float32, device=device)  # Predictions for test test\n",
    "\n",
    "# We stratify by target value, thus, according to sklearn StratifiedKFold documentation\n",
    "# We can fill `X` with zeroes of corresponding length to use it as a placeholder\n",
    "# since we only need `y` to stratify the data\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X=np.zeros(len(train)), y=train.y), 1):\n",
    "    print('=' * 20, 'Fold', fold, '=' * 20)\n",
    "    \n",
    "    best_val = None  # Best validation score within this fold\n",
    "    patience = es_patience  # Current patience counter\n",
    "    #arch = EfficientNet.from_pretrained('efficientnet-b0')  # Going to use efficientnet-b0 NN architecture\n",
    "    arch = torch.hub.load('pytorch/vision:v0.6.0', 'resnet50', pretrained=True) \n",
    "    model = Net(arch=arch)  # New model for each fold\n",
    "    model = model.to(device)\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    train_loader = DataLoader(dataset=Subset(train, train_idx), batch_size=70, shuffle=True)\n",
    "    val_loader = DataLoader(dataset=Subset(train, val_idx), batch_size=50, shuffle=False)\n",
    "    test_loader = DataLoader(dataset=test, batch_size=50, shuffle=False)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        correct = 0\n",
    "        epoch_loss = 0\n",
    "        model.train()\n",
    "        \n",
    "        for idx, (x, y) in enumerate(train_loader):\n",
    "            x = torch.tensor(x, device=device, dtype=torch.float32)\n",
    "            y = torch.tensor(y, device=device, dtype=torch.float32)\n",
    "            optim.zero_grad()\n",
    "            z = model(x)\n",
    "            loss = criterion(z, y.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            pred = torch.round(torch.sigmoid(z))  # round off sigmoid to obtain predictions\n",
    "            correct += (pred.cpu() == y.cpu().unsqueeze(1)).sum().item()  # tracking number of correctly predicted samples\n",
    "            epoch_loss += loss.item()\n",
    "            print(\"\\r{} / {}\".format(idx * 70, len(train_idx)), end=\"\")\n",
    "        print(\"finish training\")\n",
    "        \n",
    "        train_acc = correct / len(train_idx)\n",
    "\n",
    "        model.eval()  # switch model to the evaluation mode\n",
    "        val_preds = torch.zeros((len(val_idx), 1), dtype=torch.float32, device=device)\n",
    "        with torch.no_grad():  # Do not calculate gradient since we are only predicting\n",
    "            # Predicting on validation set\n",
    "            for j, (x_val, y_val) in enumerate(val_loader):\n",
    "                x_val = torch.tensor(x_val, device=device, dtype=torch.float32)\n",
    "                y_val = torch.tensor(y_val, device=device, dtype=torch.float32)\n",
    "                z_val = model(x_val)\n",
    "                val_pred = torch.sigmoid(z_val)\n",
    "                val_preds[j*x_val.shape[0]:j*x_val.shape[0] + x_val.shape[0]] = val_pred\n",
    "            val_acc = accuracy_score(train.df.iloc[val_idx]['target'].values, torch.round(val_preds.cpu()))\n",
    "            val_roc = roc_auc_score(train.df.iloc[val_idx]['target'].values, val_preds.cpu())\n",
    "            \n",
    "            print('Epoch {:03}: | Loss: {:.3f} | Train acc: {:.3f} | Val acc: {:.3f} | Val roc_auc: {:.3f} | Training time: {}'.format(\n",
    "            epoch + 1, \n",
    "            epoch_loss, \n",
    "            train_acc, \n",
    "            val_acc, \n",
    "            val_roc, \n",
    "            str(datetime.timedelta(seconds=time.time() - start_time))))\n",
    "            \n",
    "            # During the first iteration (first epoch) best validation is set to None\n",
    "            if not best_val:\n",
    "                best_val = val_roc  # So any validation roc_auc we have is the best one for now\n",
    "                torch.save(model, model_path)  # Saving the model\n",
    "                continue\n",
    "                \n",
    "            if val_roc >= best_val:\n",
    "                best_val = val_roc\n",
    "                patience = es_patience  # Resetting patience since we have new best validation accuracy\n",
    "                torch.save(model, model_path)  # Saving current best model\n",
    "            else:\n",
    "                patience -= 1\n",
    "                if patience == 0:\n",
    "                    print('Early stopping. Best Val roc_auc: {:.3f}'.format(best_val))\n",
    "                    break\n",
    "                \n",
    "    model = torch.load(model_path)  # Loading best model of this fold\n",
    "    model.eval()  # switch model to the evaluation mode\n",
    "    val_preds = torch.zeros((len(val_idx), 1), dtype=torch.float32, device=device)\n",
    "    with torch.no_grad():\n",
    "        # Predicting on validation set once again to obtain data for OOF\n",
    "        for j, (x_val, y_val) in enumerate(val_loader):\n",
    "            x_val = torch.tensor(x_val, device=device, dtype=torch.float32)\n",
    "            y_val = torch.tensor(y_val, device=device, dtype=torch.float32)\n",
    "            z_val = model(x_val)\n",
    "            val_pred = torch.sigmoid(z_val)\n",
    "            val_preds[j*x_val.shape[0]:j*x_val.shape[0] + x_val.shape[0]] = val_pred\n",
    "        oof[val_idx] = val_preds.cpu().numpy()\n",
    "        \n",
    "        # Predicting on test set\n",
    "        for i, x_test in enumerate(test_loader):\n",
    "            x_test = torch.tensor(x_test, device=device, dtype=torch.float32)\n",
    "            z_test = model(x_test)\n",
    "            z_test = torch.sigmoid(z_test)\n",
    "            preds[i*x_test.shape[0]:i*x_test.shape[0] + x_test.shape[0]] += z_test / skf.n_splits"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
